{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeres proves de models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías que vamos a estar usando en general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>ctx-4</th>\n",
       "      <th>ctx-3</th>\n",
       "      <th>ctx-2</th>\n",
       "      <th>ctx-1</th>\n",
       "      <th>percentage_docks_available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>0.469697</td>\n",
       "      <td>0.403409</td>\n",
       "      <td>0.354167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.289773</td>\n",
       "      <td>0.373106</td>\n",
       "      <td>0.304924</td>\n",
       "      <td>0.238636</td>\n",
       "      <td>0.240530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.253788</td>\n",
       "      <td>0.268939</td>\n",
       "      <td>0.350379</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.393939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.390152</td>\n",
       "      <td>0.346591</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.220930</td>\n",
       "      <td>0.186047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.218992</td>\n",
       "      <td>0.437984</td>\n",
       "      <td>0.515504</td>\n",
       "      <td>0.470930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id    year  month  day  hour     ctx-4     ctx-3     ctx-2  \\\n",
       "0         1.0  2020.0    1.0  1.0   2.0  0.522727  0.503788  0.469697   \n",
       "1         1.0  2020.0    1.0  1.0   7.0  0.289773  0.373106  0.304924   \n",
       "2         1.0  2020.0    1.0  1.0  12.0  0.253788  0.268939  0.350379   \n",
       "3         1.0  2020.0    1.0  1.0  17.0  0.390152  0.346591  0.255814   \n",
       "4         1.0  2020.0    1.0  1.0  22.0  0.083333  0.218992  0.437984   \n",
       "\n",
       "      ctx-1  percentage_docks_available  \n",
       "0  0.403409                    0.354167  \n",
       "1  0.238636                    0.240530  \n",
       "2  0.344697                    0.393939  \n",
       "3  0.220930                    0.186047  \n",
       "4  0.515504                    0.470930  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth = \"/Users/albam/Desktop/UNIVERSITAT/POSTGRAU/CAPSTONE_PROJECT/Gorrapiedra-proyecto/data/formated data\"\n",
    "\n",
    "df_20 = pd.read_csv(os.path.join(pth, \"data_2020.csv\"), index_col=False, skipinitialspace=True, skip_blank_lines=True)\n",
    "df_21 = pd.read_csv(os.path.join(pth, \"data_2021.csv\"), index_col=False, skipinitialspace=True, skip_blank_lines=True)\n",
    "df_22 = pd.read_csv(os.path.join(pth, \"data_2022.csv\"), index_col=False, skipinitialspace=True, skip_blank_lines=True)\n",
    "df_23 = pd.read_csv(os.path.join(pth, \"data_2023.csv\"), index_col=False, skipinitialspace=True, skip_blank_lines=True)\n",
    "df = pd.concat([df_20, df_21, df_22, df_23], ignore_index = True)\n",
    "\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df = df.drop(['Unnamed: 0'], axis=1)   # Eliminar columna Unnamed\n",
    "\n",
    "# Visualitzar el df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el dataset en training i test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['percentage_docks_available']\n",
    "X = df.drop(['percentage_docks_available'], axis=1)\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.3, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding\n",
    "cat_cols = ['station_id', 'month', 'day', 'year']\n",
    "x_train_encoded = pd.get_dummies(X_train, columns=cat_cols)\n",
    "x_validation_encoded = pd.get_dummies(X_validation, columns=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns in validation set: {'station_id_530.0', 'station_id_529.0'}\n",
      "Training set shape after deleting columns: (2311772, 567)\n",
      "Validation set shape: (990760, 567)\n"
     ]
    }
   ],
   "source": [
    "# Veiem que el training set y el validation set tenen diferent número de columnes després del encoding. Mirem quines son les columnes que falten al validation set.\n",
    "missing_cols = set(x_train_encoded.columns) - set(x_validation_encoded.columns)\n",
    "print(\"Missing columns in validation set:\", missing_cols)\n",
    "\n",
    "# Si hay columnas que faltan en el validation set, las borramos del training set\n",
    "for col in missing_cols:\n",
    "    x_train_encoded.drop(col, axis=1, inplace=True)\n",
    "\n",
    "print(\"Training set shape after deleting columns:\", x_train_encoded.shape)\n",
    "print(\"Validation set shape:\", x_validation_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (2311772, 567)\n",
      "Validation set shape: (990760, 567)\n"
     ]
    }
   ],
   "source": [
    "# Normalitzar les dades\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train_encoded_scal = scaler.fit_transform(x_train_encoded)\n",
    "x_validation_encoded_scal = scaler.fit_transform(x_validation_encoded)\n",
    "\n",
    "print(\"Training set shape:\", x_train_encoded_scal.shape)\n",
    "print(\"Validation set shape:\", x_validation_encoded_scal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.013253123112304682\n",
      "RMSE: 0.11512220946587448\n",
      "MAE: 0.07535876977063577\n",
      "R2: 0.8368263230097379\n"
     ]
    }
   ],
   "source": [
    "# Decision tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "dtr = DecisionTreeRegressor(max_depth=6)\n",
    "\n",
    "dtr.fit(x_train_encoded_scal, y_train)\n",
    "\n",
    "y_pred = dtr.predict(x_validation_encoded_scal)\n",
    "\n",
    "mse = mean_squared_error(y_validation, y_pred)\n",
    "rmse = mean_squared_error(y_validation, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_validation, y_pred)\n",
    "r2 = r2_score(y_validation, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R2:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/03/e6/4aef6799badc2693548559bad5b56d56cfe89eada337c815fdfe92175250/xgboost-2.0.3-py3-none-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading xgboost-2.0.3-py3-none-macosx_12_0_arm64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in /Users/albam/Applications/anaconda3/lib/python3.11/site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in /Users/albam/Applications/anaconda3/lib/python3.11/site-packages (from xgboost) (1.10.1)\n",
      "Downloading xgboost-2.0.3-py3-none-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n",
      "MSE: 0.01225244821545074\n",
      "RMSE: 0.11069077746339458\n",
      "MAE: 0.07123669394594123\n",
      "R2: 0.8491467248507131\n"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgbr = XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs=4)\n",
    "\n",
    "xgbr.fit(x_train_encoded_scal, y_train)\n",
    "\n",
    "y_pred = xgbr.predict(x_validation_encoded_scal)\n",
    "\n",
    "mse = mean_squared_error(y_validation, y_pred)\n",
    "rmse = mean_squared_error(y_validation, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_validation, y_pred)\n",
    "r2 = r2_score(y_validation, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple neural network \n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, Nin, Nhid1, Nout):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        # Define linear transformations and activation functions\n",
    "        self.actfun = nn.LeakyReLU()\n",
    "\n",
    "        self.lc1 = nn.Linear(Nin, Nhid1, bias=True)\n",
    "\n",
    "        self.lc2 = nn.Linear(Nhid1, Nout, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        o = self.lc2(self.actfun(self.lc1(x)))\n",
    "        return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "# Hiperparàmetres generals de la xarxa\n",
    "\n",
    "Nin = x_train_encoded_scal.shape[1] # nombre d'inputs\n",
    "Nout = 1 # nombre d'outputs\n",
    "lr = 0.1 #learning rate\n",
    "epochs = 30 # nombre d'iteracions\n",
    "\n",
    "# Parametres de la xarxa    \n",
    "Nhid1 = 5\n",
    "\n",
    "# Creem la xarxa\n",
    "model = NeuralNetwork(Nin=Nin, Nhid1=Nhid1,  Nout=Nout)\n",
    "\n",
    "# Optimitzador\n",
    "optimizer = torch.optim.Rprop(params=model.parameters(), lr=lr)\n",
    "#optimizer = torch.optim.Adam(params=model.to(device).parameters(), lr=lr)\n",
    "loss_fn = nn.MSELoss()\n",
    "#loss_fn = nn.SmoothL1Loss() # L1 loss\n",
    "\n",
    "net = model.to(device) # instanciem l'objecte\n",
    "\n",
    "print('NN architecture: \\n', net)\n",
    "print(\"Layers and parameters:\\n\")\n",
    "for name, param in net.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:50]} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(f\"x_train_encoded_scal shape: {x_train_encoded_scal.shape}, dtype: {x_train_encoded_scal.dtype}\")\n",
    "print(f\"y_train shape: {y_train.shape}, dtype: {y_train.dtype}\")\n",
    "print(f\"x_validation_encoded_scal shape: {x_validation_encoded_scal.shape}, dtype: {x_validation_encoded_scal.dtype}\")\n",
    "print(f\"y_validation shape: {y_validation.shape}, dtype: {y_validation.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import psutil\n",
    "\n",
    "def get_memory_usage():\n",
    "    mem = psutil.virtual_memory()\n",
    "    total_memory = mem.total / (1024 ** 3)  # Convert bytes to GB\n",
    "    available_memory = mem.available / (1024 ** 3)  # Convert bytes to GB\n",
    "    used_memory = total_memory - available_memory\n",
    "    percent_used = (used_memory / total_memory) * 100\n",
    "    return available_memory, used_memory, percent_used\n",
    "\n",
    "available_memory, used_memory, percent_used = get_memory_usage()\n",
    "print(f\"Available memory: {available_memory:.2f} GB\")\n",
    "print(f\"Used memory: {used_memory:.2f} GB\")\n",
    "print(f\"Percentage used: {percent_used:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss_list_tr = []\n",
    "loss_list_val = []\n",
    "print(\"hello\")\n",
    "\n",
    "try:\n",
    "    print(\"Converting and moving training data...\")\n",
    "    train_set = torch.tensor(x_train_encoded_scal.reshape(-1,1), dtype=torch.float32).detach().to(device)\n",
    "    print(\"Train set loaded successfully\")\n",
    "    \n",
    "    target = torch.tensor(y_train, dtype=torch.float32).squeeze().detach().to(device)\n",
    "    print(\"Target loaded successfully\")\n",
    "    \n",
    "    validation_set = torch.tensor(x_validation_encoded_scal.reshape(-1,1), dtype=torch.float32).detach().to(device)\n",
    "    print(\"Validation set loaded successfully\")\n",
    "    \n",
    "    validation = torch.tensor(y_validation, dtype=torch.float32).squeeze().detach().to(device)\n",
    "    print(\"Validation target loaded successfully\")\n",
    "except RuntimeError as e:\n",
    "    print(\"RuntimeError:\", e)\n",
    "except Exception as e:\n",
    "    print(\"Exception:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from torch.utils.data import  DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_set, batch_size=batch_size, shuffle=False)\n",
    "target_loader_train = DataLoader(target, batch_size=batch_size, shuffle=True)\n",
    "target_loader_val = DataLoader(validation, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r_training = trange(epochs, desc=\"Training\", leave=True, colour=\"blue\")\n",
    "for t in r_training:\n",
    "    print(t)\n",
    "\n",
    "    model.train(True)\n",
    "    optimizer.zero_grad()\n",
    "    pred = net(train_set).squeeze()  # predicció\n",
    "    loss = loss_fn(pred, target)  # càlcul del cost\n",
    "    loss_list_tr.append(loss.item())\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        val = net(validation_set).squeeze()\n",
    "    loss_v = loss_fn(val, validation)  # càlcul del cost\n",
    "    loss_list_val.append(loss_v.item())\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Plots\n",
    "    if t%10 == 0 or t == epochs - 1: # or (t + 1) % 200 == 0 or t == epochs - 1:\n",
    "        plt.plot(loss_list_tr, label='Training loss')\n",
    "        plt.plot(loss_list_val, label='Validation loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    r_training.set_postfix_str(\"L1: %6.4f\" % (loss.item()))\n",
    "\n",
    "r_training.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
